(ns docai.advanced-rag
  (:require [clojure.string :as str]
            [clojure.data.json :as json]
            [next.jdbc :as jdbc]
            [next.jdbc.result-set :as rs]
            [docai.llm :as llm]
            [docai.pg :as pg]))

;; Cache para embeddings
(def embedding-cache (atom {}))
(def response-cache (atom {}))

;; Configura√ß√£o de cache
(def cache-ttl (* 60 60 24)) ;; 24 horas em segundos
(def max-cache-size 1000)

;; Pr√©-declara√ß√£o de fun√ß√µes para evitar refer√™ncias circulares
(declare advanced-rag-query advanced-semantic-search analyze-query-complexity personal-query? sliding-window-chunks dynamic-semantic-search)

(defn cached-embedding
  "Gera embedding para texto com cache"
  [text db-spec]
  (if-let [cached (@embedding-cache text)]
    (do
      (println "Cache hit para embedding!")
      cached)
    (let [conn (jdbc/get-connection db-spec)
          embedding-sql "SELECT ai.ollama_embed('nomic-embed-text', ?) AS embedding"
          result (try
                   (jdbc/execute-one! conn [embedding-sql text]
                                     {:builder-fn rs/as-unqualified-maps})
                   (catch Exception e
                     (println "Erro ao gerar embedding:" (.getMessage e))
                     nil))
          embedding (:embedding result)]
      (.close conn)
      (when embedding
        (swap! embedding-cache 
               (fn [cache]
                 (let [updated-cache (assoc cache text embedding)]
                   ;; Limitar tamanho do cache
                   (if (> (count updated-cache) max-cache-size)
                     (into {} (take max-cache-size updated-cache))
                     updated-cache)))))
      embedding)))


;; Fun√ß√£o principal para processamento RAG avan√ßado
(defn advanced-rag-query
  "Processa uma consulta usando RAG avan√ßado"
  [query]
  (let [;; Verificar cache primeiro
        cached (get @response-cache query)
        current-time (System/currentTimeMillis)]
    
    (if (and cached (< (- current-time (:timestamp cached)) (* cache-ttl 1000)))
      ;; Retornar do cache se dispon√≠vel e n√£o expirado
      (:response cached)
      
      ;; Caso contr√°rio, processar a consulta
      (let [;; Analisar complexidade da consulta
            query-complexity (analyze-query-complexity query)
            start-time (System/currentTimeMillis)]
        
        (println "Complexidade da consulta:" query-complexity)
        
        (let [;; Usar busca sem√¢ntica com chunking din√¢mico
              docs (dynamic-semantic-search query 5)
              ;; Fallback para busca sem√¢ntica padr√£o se n√£o houver resultados din√¢micos
              final-docs (if (seq docs)
                           docs
                           (advanced-semantic-search query 5))
              context (->> final-docs
                         (map :content)
                         (str/join "\n\n"))
              prompt (llm/format-prompt context query)
              response (llm/call-ollama-api prompt)
              
              ;; Calcular tempo total
              total-time (- (System/currentTimeMillis) start-time)]
          
          ;; Log para an√°lise
          (println "Consulta processada em" total-time "ms")
          
          ;; Atualizar cache se n√£o for consulta pessoal
          (when (not (personal-query? query))
            (swap! response-cache assoc query {:response response
                                              :timestamp (System/currentTimeMillis)}))
          
          response)))))

(defn cached-rag-query
  "Executa consulta RAG com cache"
  [query]
  (if-let [cached (@response-cache query)]
    (do
      (println "Cache hit para consulta!")
      cached)
    (let [;; Processo RAG completo
          response (advanced-rag-query query)]
      ;; Armazenar no cache apenas para consultas n√£o-pessoais
      (when (not (personal-query? query))
        (swap! response-cache 
               (fn [cache]
                 (let [updated-cache (assoc cache query {:response response
                                                        :timestamp (System/currentTimeMillis)})]
                   ;; Limitar tamanho do cache
                   (if (> (count updated-cache) max-cache-size)
                     (into {} (take max-cache-size updated-cache))
                     updated-cache)))))
      response)))

(defn personal-query?
  "Verifica se a consulta cont√©m informa√ß√µes pessoais que n√£o devem ser cacheadas"
  [query]
  (let [lower-query (str/lower-case query)
        personal-patterns ["meu" "minha" "nosso" "nossa" "eu" "n√≥s"]]
    (some #(str/includes? lower-query %) personal-patterns)))

(defn cleanup-cache
  "Remove entradas expiradas do cache"
  []
  (let [current-time (System/currentTimeMillis)
        expiry-time-ms (* cache-ttl 1000)]
    (swap! response-cache
           (fn [cache]
             (into {} (filter (fn [[_ v]]
                                (< (- current-time (:timestamp v)) expiry-time-ms))
                              cache))))))

;; Estrat√©gias de chunking
(defn adaptive-chunking-strategy
  "Determina estrat√©gia de chunking com base no tipo de documento"
  [document-type]
  (case document-type
    "article" {:chunk-size 1000 :chunk-overlap 150}
    "code" {:chunk-size 500 :chunk-overlap 50}
    "legal" {:chunk-size 1500 :chunk-overlap 200}
    "qa" {:chunk-size 800 :chunk-overlap 100}
    ;; Default
    {:chunk-size 1000 :chunk-overlap 100}))

(defn sliding-window-chunks
  "Divide texto em chunks de tamanho fixo com sobreposi√ß√£o"
  [text chunk-size chunk-overlap]
  (let [stride (- chunk-size chunk-overlap)]
    (loop [start 0
           result []]
      (if (>= start (count text))
        result
        (let [end (min (+ start chunk-size) (count text))
              chunk (subs text start end)]
          (recur (+ start stride)
                 (conj result chunk)))))))

(defn recursive-text-splitter
  "Implementa√ß√£o de chunking recursivo que respeita a estrutura do documento"
  [text {:keys [chunk-size chunk-overlap]}]
  (let [;; Tentar dividir por se√ß√µes (cabe√ßalhos)
        sections (re-seq #"(?m)^#{1,6}\s+.*$\n(?:(?!^#{1,6}\s+).*\n)*" text)]
    (if (and sections (> (count sections) 1))
      ;; Se conseguiu dividir por se√ß√µes, processar cada se√ß√£o
      (mapcat #(recursive-text-splitter % {:chunk-size chunk-size :chunk-overlap chunk-overlap}) sections)
      ;; Caso contr√°rio, dividir por par√°grafos
      (let [paragraphs (re-seq #"(?m)^.*(?:\n(?!\s*\n).*)*" text)]
        (if (and paragraphs (> (count paragraphs) 1))
          ;; Se conseguiu dividir por par√°grafos, processar cada par√°grafo grande
          (mapcat (fn [p]
                    (if (> (count p) chunk-size)
                      ;; Dividir par√°grafos grandes em chunks com sobreposi√ß√£o
                      (sliding-window-chunks p chunk-size chunk-overlap)
                      [p]))
                  paragraphs)
          ;; √öltimo recurso: divis√£o por tamanho fixo
          (sliding-window-chunks text chunk-size chunk-overlap))))))

(defn dynamic-chunk-document
  "Processa um documento usando chunking din√¢mico adaptado ao tipo de conte√∫do"
  [document-id content document-type]
  (let [;; Obter estrat√©gia de chunking apropriada para o tipo de documento
        chunking-params (adaptive-chunking-strategy document-type)
        ;; Aplicar chunking din√¢mico
        chunks (recursive-text-splitter content chunking-params)]
    
    (println "Documento " document-id " dividido em " (count chunks) " chunks usando estrat√©gia para tipo " document-type)
    
    ;; Retornar chunks com metadados
    (map-indexed 
     (fn [idx chunk] 
       {:document_id document-id
        :chunk_id (str document-id "-" idx)
        :content chunk
        :chunk_type document-type
        :chunk_index idx
        :total_chunks (count chunks)})
     chunks)))

;; Reimplementa√ß√£o de vetoriza√ß√£o com chunking adaptativo
(defn create-vectorizer-with-adaptive-chunking!
  "Configura vectorizer com chunking adaptativo"
  [document-type]
  (let [conn (jdbc/get-connection pg/db-spec)
        {:keys [chunk-size chunk-overlap]} (adaptive-chunking-strategy document-type)
        table-name (str "documentos_embeddings_" document-type)
        
        ;; Tenta criar o vectorizer e captura erros espec√≠ficos de "j√° existe"
        vectorizer-sql (str "SELECT ai.create_vectorizer(
                             'documentos'::regclass,
                             destination => 'documentos_embeddings_" document-type "',
                             embedding => ai.embedding_ollama('nomic-embed-text', 768),
                             chunking => ai.chunking_recursive_character_text_splitter('conteudo', 
                                                                                    chunk_size => " chunk-size ")
                           )")]
    
    (try
      (println "Tentando criar vectorizer para" table-name "...")
      (jdbc/execute! conn [vectorizer-sql])
      (println "‚úÖ Vectorizer para tipo" document-type "configurado com sucesso")
      
      (catch Exception e
        (let [error-msg (.getMessage e)]
          ;; Verifica se o erro √© devido a tabela j√° existir
          (if (str/includes? error-msg "already exists")
            (println "‚úÖ Vectorizer para tipo" document-type "j√° existe, ignorando cria√ß√£o.")
            
            ;; Se for outro tipo de erro, tenta abordagem simplificada
            (do
              (println "‚ùå Erro ao configurar vectorizer:" (.getMessage e))
              
              ;; Tentar abordagem alternativa sem par√¢metros adicionais
              (try
                (println "üîÑ Tentando abordagem alternativa simplificada...")
                (let [simple-sql (str "SELECT ai.create_vectorizer(
                                    'documentos'::regclass,
                                    destination => 'documentos_embeddings_" document-type "',
                                    embedding => ai.embedding_ollama('nomic-embed-text', 768),
                                    chunking => ai.chunking_recursive_character_text_splitter('conteudo')
                                  )")]
                  (jdbc/execute! conn [simple-sql])
                  (println "‚úÖ Vectorizer (vers√£o simplificada) configurado com sucesso"))
                (catch Exception e2
                  (let [error-msg2 (.getMessage e2)]
                    (if (str/includes? error-msg2 "already exists")
                      (println "‚úÖ Vectorizer para tipo" document-type "j√° existe, ignorando cria√ß√£o.")
                      (println "‚ùå Erro na abordagem alternativa:" (.getMessage e2)))))))))))
    
    (.close conn)))

;; Fun√ß√£o para processar um documento com chunking din√¢mico e inserir no banco
(defn process-document-with-dynamic-chunking!
  "Processa um documento com chunking din√¢mico e insere os chunks no banco de dados"
  [document-id content document-type]
  (let [;; Gerar chunks usando chunking din√¢mico
        chunks (dynamic-chunk-document document-id content document-type)
        conn (jdbc/get-connection pg/db-spec)
        
        ;; Verificar se a tabela de chunks existe, criar se necess√°rio
        _ (try
            (jdbc/execute! conn ["CREATE TABLE IF NOT EXISTS document_chunks (
                                 id SERIAL PRIMARY KEY,
                                 document_id TEXT NOT NULL,
                                 chunk_id TEXT NOT NULL UNIQUE,
                                 content TEXT NOT NULL,
                                 chunk_type TEXT NOT NULL,
                                 chunk_index INTEGER NOT NULL,
                                 total_chunks INTEGER NOT NULL,
                                 embedding VECTOR(768) NULL,
                                 created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                               )"])
            (catch Exception e
              (println "Aviso: Erro ao criar tabela de chunks:" (.getMessage e))))]
    
    ;; Inserir cada chunk no banco
    (doseq [chunk chunks]
      (try
        (jdbc/execute! conn ["INSERT INTO document_chunks 
                             (document_id, chunk_id, content, chunk_type, chunk_index, total_chunks)
                             VALUES (?, ?, ?, ?, ?, ?)
                             ON CONFLICT (chunk_id) DO NOTHING"
                           (:document_id chunk)
                           (:chunk_id chunk)
                           (:content chunk)
                           (:chunk_type chunk)
                           (:chunk_index chunk)
                           (:total_chunks chunk)])
        (catch Exception e
          (println "Erro ao inserir chunk" (:chunk_id chunk) ":" (.getMessage e)))))
    
    ;; Gerar embeddings para os novos chunks
    (println "Gerando embeddings para chunks do documento" document-id "...")
    (try
      (jdbc/execute! conn ["UPDATE document_chunks 
                           SET embedding = ai.ollama_embed('nomic-embed-text', content) 
                           WHERE document_id = ? AND embedding IS NULL"
                         document-id])
      (catch Exception e
        (println "Erro ao gerar embeddings:" (.getMessage e))))
    
    (.close conn)
    
    (println "‚úÖ Documento" document-id "processado com chunking din√¢mico e armazenado com sucesso.")
    (count chunks)))

;; Fun√ß√£o avan√ßada para busca sem√¢ntica usando os chunks din√¢micos
(defn dynamic-semantic-search
  "Realiza busca sem√¢ntica em chunks gerados dinamicamente"
  [query limit]
  (let [conn (jdbc/get-connection pg/db-spec)
        ;; Gerar embedding para a consulta
        query-embedding (cached-embedding query pg/db-spec)
        
        ;; Buscar chunks mais pr√≥ximos
        results (when query-embedding
                  (try
                    (jdbc/execute! 
                     conn
                     ["SELECT 
                       c.document_id,
                       c.chunk_id,
                       c.content,
                       c.chunk_type,
                       c.chunk_index,
                       c.total_chunks,
                       1 - (c.embedding <=> ?) AS similarity
                       FROM document_chunks c
                       WHERE c.embedding IS NOT NULL
                       ORDER BY c.embedding <=> ?
                       LIMIT ?"
                      query-embedding
                      query-embedding
                      limit]
                     {:builder-fn rs/as-unqualified-maps})
                    (catch Exception e
                      (println "Erro na busca sem√¢ntica din√¢mica:" (.getMessage e))
                      [])))]
    
    (.close conn)
    results))

;; Implementa√ß√£o de reranking
(defn rerank-results
  "Re-classifica resultados usando scoring avan√ßado"
  [query initial-results]
  (let [;; Calcular scores mais sofisticados para cada resultado
        results-with-scores (map 
                             (fn [doc]
                               (let [;; Combina m√∫ltiplos fatores na pontua√ß√£o
                                     ;; 1. Dist√¢ncia original de embedding (j√° temos)
                                     emb-score (:distancia doc)
                                     
                                     ;; 2. Correspond√™ncia de palavras-chave
                                     query-words (-> query
                                                   str/lower-case
                                                   (str/split #"\s+")
                                                   set)
                                     content-lower (str/lower-case (:conteudo doc))
                                     keyword-matches (count (filter #(str/includes? content-lower %) query-words))
                                     keyword-score (/ keyword-matches (max 1 (count query-words)))
                                     
                                     ;; 3. Comprimento do documento (prefer√™ncia para respostas mais concisas)
                                     length-factor (Math/max 0.5 (Math/min 1.0 (/ 2000.0 (count (:conteudo doc)))))
                                     
                                     ;; Score combinado (quanto menor, melhor)
                                     combined-score (+ (* 0.6 emb-score)
                                                      (* -0.3 keyword-score) ;; Negativo porque queremos maximizar correspond√™ncias
                                                      (* 0.1 (- 1.0 length-factor)))]
                                 (assoc doc :relevance_score combined-score)))
                             initial-results)
        
        ;; Ordenar por score combinado (do menor para o maior)
        reranked-results (sort-by :relevance_score results-with-scores)]
    
    reranked-results))

;; Busca sem√¢ntica avan√ßada com reranking
(defn advanced-semantic-search
  "Realiza busca sem√¢ntica avan√ßada com re-ranqueamento"
  [query limit]
  (let [conn (jdbc/get-connection pg/db-spec)
        ;; Etapa 1: Recupera√ß√£o inicial usando embeddings
        initial-results (try
                          (jdbc/execute! 
                           conn
                           ["WITH query_embedding AS (
                              SELECT ai.ollama_embed('nomic-embed-text', ?) AS embedding
                            )
                            SELECT
                              d.id,
                              d.titulo,
                              d.conteudo,
                              d.categoria,
                              e.embedding <=> (SELECT embedding FROM query_embedding) AS distancia
                            FROM documentos d
                            JOIN documentos_embeddings e ON d.id = e.id
                            ORDER BY distancia
                            LIMIT 20"
                            query]
                           {:builder-fn rs/as-unqualified-maps})
                          (catch Exception e
                            (println "Erro na busca inicial:" (.getMessage e))
                            []))
        
        ;; Etapa 2: Re-ranqueamento para melhorar precis√£o
        reranked-results (if (> (count initial-results) 1)
                           (rerank-results query initial-results)
                           initial-results)]
    
    (.close conn)
    
    ;; Retornar apenas o n√∫mero solicitado de resultados
    (take limit reranked-results)))

;; An√°lise de complexidade da consulta
(defn analyze-query-complexity
  "Analisa a complexidade da consulta para escolher a estrat√©gia adequada"
  [query]
  (let [lower-query (str/lower-case query)
        ;; Padr√µes que indicam consultas complexas
        complex-patterns ["como" "explique" "compare" "diferen√ßa entre" "quando devo"
                          "melhor maneira" "vantagens e desvantagens" "pros e contras"]
        ;; Padr√µes que indicam necessidade de dados estruturados
        structured-patterns ["tabela" "lista" "valor" "n√∫mero" "quantidade" 
                             "estat√≠stica" "percentual" "quanto" "valores"]]
    (cond
      (some #(str/includes? lower-query %) complex-patterns) :complex
      (some #(str/includes? lower-query %) structured-patterns) :structured-data
      :else :simple)))



(defn setup-advanced-rag!
  "Configura o ambiente para RAG avan√ßado"
  []
  (println "Configurando ambiente para RAG avan√ßado...")
  
  ;; Verificar se o PostgreSQL est√° acess√≠vel
  (if (pg/check-postgres-connection)
    (do
      ;; Configurar vectorizadores para diferentes tipos de documentos
      (create-vectorizer-with-adaptive-chunking! "article")
      (create-vectorizer-with-adaptive-chunking! "code")
      
      ;; Criar tabela para chunks din√¢micos
      (let [conn (jdbc/get-connection pg/db-spec)]
        (try
          (jdbc/execute! conn ["CREATE TABLE IF NOT EXISTS document_chunks (
                               id SERIAL PRIMARY KEY,
                               document_id TEXT NOT NULL,
                               chunk_id TEXT NOT NULL UNIQUE,
                               content TEXT NOT NULL, 
                               chunk_type TEXT NOT NULL,
                               chunk_index INTEGER NOT NULL,
                               total_chunks INTEGER NOT NULL,
                               embedding VECTOR(768) NULL,
                               created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                             )"])
          (println "‚úÖ Tabela para chunks din√¢micos configurada com sucesso")
          (catch Exception e
            (println "‚ö†Ô∏è Erro ao criar tabela de chunks din√¢micos:" (.getMessage e))))
        (.close conn))
      
      ;; Iniciar limpeza peri√≥dica de cache
      (future
        (while true
          (try
            (cleanup-cache)
            (catch Exception e
              (println "Erro na limpeza do cache:" (.getMessage e))))
          (Thread/sleep (* 60 60 1000)))) ;; Executar a cada hora
      
      (println "‚úÖ RAG avan√ßado configurado com sucesso!"))
    (println "‚ùå Falha na configura√ß√£o do RAG avan√ßado: PostgreSQL n√£o acess√≠vel"))) 